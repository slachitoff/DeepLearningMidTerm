{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMUeQdbs8SBG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "\n",
        "from torchvision.transforms import ToPILImage\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "#Function to load a pickle file\n",
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "#Function to load a CIFAR-10 batch file\n",
        "def load_cifar10_batch(batch_filename):\n",
        "    batch = unpickle(batch_filename)\n",
        "    images = batch[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "    labels = batch[b'labels']\n",
        "    return images, labels\n",
        "\n",
        "#Loaf images and labels from CIFAR-10 batch files\n",
        "train_images1, train_labels1 = load_cifar10_batch('/content/data_batch_1')\n",
        "train_images2, train_labels2 = load_cifar10_batch('/content/data_batch_2')\n",
        "train_images3, train_labels3 = load_cifar10_batch('/content/data_batch_3')\n",
        "train_images4, train_labels4 = load_cifar10_batch('/content/data_batch_4')\n",
        "train_images5, train_labels5 = load_cifar10_batch('/content/data_batch_5')\n",
        "\n",
        "#Combine all batch files into one array for images and labels\n",
        "original_train_images = np.concatenate((train_images1, train_images2, train_images3, train_images4, train_images5))\n",
        "original_train_labels = np.concatenate((train_labels1, train_labels2, train_labels3, train_labels4, train_labels5))\n",
        "\n",
        "#Define transformations for training images\n",
        "transform_train = transforms.Compose([\n",
        "    ToPILImage(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(degrees=5),\n",
        "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "#Define transformations for testing and validation images\n",
        "transform_test = transforms.Compose([\n",
        "    ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "#Calculate the number of training and validation samples\n",
        "num_train = int(0.95 * len(original_train_images))\n",
        "num_val = len(original_train_images) - num_train\n",
        "\n",
        "#Randomly shuffle the indices of the images\n",
        "shuffled_indices = np.random.permutation(len(original_train_images))\n",
        "\n",
        "#Split indices for training and validation sets\n",
        "train_idx = shuffled_indices[:num_train]\n",
        "val_idx = shuffled_indices[num_train:]\n",
        "\n",
        "#Create subsets for validation/trianing images and labels based on shuffled incides\n",
        "train_images_subset = original_train_images[train_idx]\n",
        "val_images_subset = original_train_images[val_idx]\n",
        "train_labels_subset = original_train_labels[train_idx]\n",
        "val_labels_subset = original_train_labels[val_idx]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a custom class for CIFAR-10 dataset\n",
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels  .\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.images[index], self.labels[index]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "#Define the batch sizes for training and validation datasets\n",
        "BATCH_SIZE_TRAIN = 128\n",
        "BATCH_SIZE_TEST = 100\n",
        "\n",
        "#Create training and validation datasets using the CIFAR10Dataset class\n",
        "train_dataset = CIFAR10Dataset(train_images_subset, train_labels_subset, transform=transform_train)\n",
        "val_dataset = CIFAR10Dataset(val_images_subset, val_labels_subset, transform=transform_test)\n",
        "\n",
        "#Create a DataLoader for the training set\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=2)\n",
        "\n",
        "#Create a DataLoader for the validation set\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "YoFTjRB_9t1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PreActBlock definition from https://github.com/kuangliu/pytorch-cifar/blob/master/models/preact_resnet.py\n",
        "#Modified to incorporate dropout layers\n",
        "class PreActBlock(nn.Module):\n",
        "class PreActBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, dropout_rate=0.0):\n",
        "        super(PreActBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(x))\n",
        "        shortcut = self.shortcut(x) if hasattr(self, 'shortcut') else x\n",
        "        out = self.conv1(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out += shortcut\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "#PreResNet definition from https://github.com/kuangliu/pytorch-cifar/blob/master/models/preact_resnet.py\n",
        "#Modified to incorporate dropout layers\n",
        "class PreActResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, dropout_rate=0.0):\n",
        "        super(PreActResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1, dropout_rate=dropout_rate)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2, dropout_rate=dropout_rate)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2, dropout_rate=dropout_rate)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2, dropout_rate=dropout_rate)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride, dropout_rate):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride, dropout_rate))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "HOzZk0g7-MOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Initialize an instance of the PreActResNet model consisting of two blocks in the first stage, with 1 block in each of the subsequent stages\n",
        "#Used to reduce the overall parameter count to <5 million\n",
        "model = PreActResNet(PreActBlock, [2, 1, 1, 1], num_classes=10, dropout_rate=0.0)\n",
        "\n",
        "#Uncomment the following code to load a pretrained model from a file:\n",
        "\n",
        "# state_dict = torch.load('/content/model.pt')\n",
        "# model.load_state_dict(state_dict)\n",
        "\n",
        "#Move the model to the designated device\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "2M5fGOYd-mIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#Display a summary of the model architecture, including the number of parameters, given an input from the CIFAR-10 dataset\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "id": "-JtD2p7q_LkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "#Define the training process for a single epoch\n",
        "def train_epoch(model, optimizer, data_loader, criterion, device, loss_history, accuracy_history):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for data, target in data_loader:\n",
        "        data, target = data.to(device), target.to(device) #Move the data to the designated device\n",
        "        optimizer.zero_grad() #Erase any gradient from previous iterations\n",
        "        output = model(data) #Compute the output of the model\n",
        "        loss = criterion(output, target) #Calculate the loss\n",
        "        loss.backward() #Perform backpropagation\n",
        "        optimizer.step() #Update model weights\n",
        "        scheduler.step() #Modify the learning ratte based on the scheduler\n",
        "\n",
        "        total_loss += loss.item() #Accumulate total loss from the batch\n",
        "        _, predicted = torch.max(output.data, 1) #Determine the predicted class\n",
        "        total += target.size(0) #Count total samples processed\n",
        "        correct += (predicted == target).sum().item() #Count correct predictions\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader) #Calcualte average loss over the entire epoch\n",
        "    accuracy = 100. * correct / total #Calculate percentage of correct predictions\n",
        "    print(f'Training: Average Loss: {avg_loss:.4f}, Accuracy: {correct}/{total} ({accuracy:.0f}%)')\n",
        "    loss_history.append(avg_loss) #Store the average loss\n",
        "    accuracy_history.append(accuracy) #Store the accuracy\n",
        "\n",
        "#Define the validation process\n",
        "def validate(model, data_loader, criterion, device, loss_history, accuracy_history):\n",
        "    model.eval() #Set model to evaluation mode\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad(): #Disable gradient calculations\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device) #Move the data to the designated device\n",
        "            output = model(data) #Compute the output of the model\n",
        "            loss = criterion(output, target) #Calculate the loss\n",
        "            val_loss += loss.item() #Accumulate total loss from the batch\n",
        "            _, predicted = torch.max(output.data, 1) #Determine the predicted class\n",
        "            correct += (predicted == target).sum().item() #Count correct predictions\n",
        "\n",
        "    avg_loss = val_loss / len(data_loader) #Calcualte average validation loss\n",
        "    accuracy = 100. * correct / len(data_loader.dataset) #Calculate validation accuracy\n",
        "    print(f'Validation: Average Loss: {avg_loss:.4f}, Accuracy: {correct}/{len(data_loader.dataset)} ({accuracy:.0f}%)')\n",
        "    loss_history.append(avg_loss) #Store average validation loss\n",
        "    accuracy_history.append(accuracy) #Store validation accuracy\n",
        "\n",
        "#Set up training parameters\n",
        "N_EPOCHS = 600\n",
        "optimizer = AdamW(model.parameters(), lr=0.015, weight_decay=0.005)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = OneCycleLR(optimizer, max_lr=0.015, steps_per_epoch=len(train_loader), epochs=N_EPOCHS)\n",
        "\n",
        "#Initialize storage for tracking progress\n",
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "val_loss_history = []\n",
        "val_accuracy_history = []\n",
        "\n",
        "start_time = time.time() #Record training start time\n",
        "\n",
        "#Define training loop\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "    print(f'\\nEpoch {epoch}/{N_EPOCHS}')\n",
        "    train_epoch(model, optimizer, train_loader, criterion, device, train_loss_history, train_accuracy_history) #Train for a single epoch\n",
        "    validate(model, val_loader, criterion, device, val_loss_history, val_accuracy_history) #Perform validation\n",
        "\n",
        "#Calculate and print total training time\n",
        "execution_time = time.time() - start_time\n",
        "print(f'\\nExecution time: {execution_time:.2f} seconds')"
      ],
      "metadata": {
        "id": "bCC7JXAK_lb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model parameters to a file called \"model.pt\"\n",
        "torch.save(model.state_dict(), 'model.pt')"
      ],
      "metadata": {
        "id": "6UbHMfvHCdYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "#Load the test batch from the specified loaction\n",
        "test_images, test_labels = load_cifar10_batch('/content/test_batch')\n",
        "\n",
        "#Define transformations for the test images\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "#Apply transformations to each image in the test set and stack them into a tensor\n",
        "test_images_tensor = torch.stack([transform_test(Image.fromarray(img)) for img in test_images])\n",
        "\n",
        "#Convert test labels into a tensor\n",
        "test_labels_tensor = torch.tensor(test_labels)\n",
        "\n",
        "#Create a TensorDataset to manage image-label pairs\n",
        "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
        "\n",
        "#DataLoader for the test batch\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "model.eval() #Set model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device) #Send images to the device\n",
        "        labels = labels.to(device) #Send labels to the device\n",
        "\n",
        "        outputs = model(images) #Compute model outputs\n",
        "        _, predicted = torch.max(outputs.data, 1) #Predict the class\n",
        "        total += labels.size(0) #Increase total count\n",
        "        correct += (predicted == labels).sum().item() #Count correct predictions\n",
        "\n",
        "test_accuracy = 100.0 * correct / total\n",
        "print(f'Accuracy on the test set: {test_accuracy}%') #Print test accuracy\n"
      ],
      "metadata": {
        "id": "7p33DVkjDA0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "#Define function to load data from a pickle file\n",
        "def load_pickle_file(filename):\n",
        "    with open(filename, 'rb') as file:\n",
        "        data = pickle.load(file)\n",
        "    return data\n",
        "\n",
        "\n",
        "unlabeled_test_data = load_pickle_file('/content/cifar_test_nolabels.pkl') # Load unlabled test data from the pickle file\n",
        "num_images = unlabeled_test_data[b'data'].shape[0] #Store the number of images\n",
        "test_images = unlabeled_test_data[b'data'].reshape((num_images, 3, 32, 32)).transpose((0, 2, 3, 1)) #Reshape and transpose test set\n",
        "\n",
        "transformed_images = [transform_test(Image.fromarray(img)) for img in test_images] #Apply previously defined transformations\n",
        "\n",
        "predictions = [] #Store predictions\n",
        "\n",
        "#Perform predictions without updating model weights\n",
        "with torch.no_grad():\n",
        "    for i, img in enumerate(transformed_images):\n",
        "        img = img.unsqueeze(0).to(device) #Add a batch dimension and send the image to a device\n",
        "        outputs = model(img) #Get output from model\n",
        "        _, predicted = torch.max(outputs, 1) #Predict the class\n",
        "        predictions.append((i, predicted.item())) #Append image index and predicted class\n",
        "\n",
        "\n",
        "df_predictions = pd.DataFrame(predictions, columns=[\"ID\", \"Labels\"]) #Create a DataFrame from the \"predictions\" list\n",
        "df_predictions.to_csv('/content/predicted_labels.csv', index=False) #Svae predictions to a CSV file called \"predicted_labels\"\n"
      ],
      "metadata": {
        "id": "dy0D2ZS6Ga_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}